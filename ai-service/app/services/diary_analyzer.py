import os
import json
import time
from datetime import datetime
from typing import List, Optional, Tuple

import openai
from dotenv import load_dotenv
import chromadb
from chromadb.utils.embedding_functions import SentenceTransformerEmbeddingFunction
import torch
import torch.nn.functional as F
import numpy as np
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

from app.models.diary import DiaryAnalysisResponse, DiaryChunk, EmotionSituationExtraction

# í™˜ê²½ì„¤ì •
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

class DiaryAnalyzer:
    """ì¼ê¸° ë¶„ì„ ë° ì½”ë©˜íŠ¸ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # ChromaDB ì„¤ì •
        self.diary_embedding_function = SentenceTransformerEmbeddingFunction(
            model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
        )
        self.general_embedding_function = SentenceTransformerEmbeddingFunction(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        
        self.client = chromadb.PersistentClient(path="./chroma_rag")
        self.pre_diary_col = self.client.get_or_create_collection(
            name="diary_past_diaries", 
            embedding_function=self.diary_embedding_function
        )
        self.advice_col = self.client.get_or_create_collection(
            name="diary_advice", 
            embedding_function=self.general_embedding_function
        )
        self.quote_col = self.client.get_or_create_collection(
            name="diary_quotes", 
            embedding_function=self.general_embedding_function
        )
    
    def preprocess_diary(self, raw_diary: str, max_retries: int = 3) -> str:
        """ì¼ê¸° ì „ì²˜ë¦¬ - ë¬¸ë²• ë° ë¬¸ë§¥ ì •ë¦¬"""
        prompt = f"""
ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì“´ ì¼ê¸°ì…ë‹ˆë‹¤.  
ì´ ì¼ê¸°ë¥¼ ë¬¸ë²•ì ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹¤ë“¬ê³ , ë¬¸ë§¥ íë¦„ë„ ë§¤ë„ëŸ½ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.  
ë‚´ìš©ì„ ë°”ê¾¸ì§€ ë§ê³ , í‘œí˜„ì„ ë‹¤ë“¬ê¸°ë§Œ í•˜ì„¸ìš”.

ğŸ“œ ì›ë³¸ ì¼ê¸°:
{raw_diary}

ğŸ“¦ ì¶œë ¥ í˜•ì‹:
```text
(ìˆ˜ì •ëœ ì¼ê¸° ì „ì²´ ë¬¸ì¥)
```
"""
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ë¬¸ì¥ êµì •ì— íŠ¹í™”ëœ í•œêµ­ì–´ í¸ì§‘ê¸°ì•¼. ì¼ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê³ ì³ì¤˜."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )
                content = response.choices[0].message.content.strip()
                if "```" in content:
                    content = content.split("```")[1].strip()
                return content
            except Exception as e:
                print(f"âš ï¸ ì¼ê¸° ì „ì²˜ë¦¬ ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        return raw_diary
    
    def chunk_diary_by_meaning(self, diary_text: str, max_retries: int = 3) -> List[str]:
        """ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì¼ê¸° ì²­í¬ ë¶„í• """
        prompt = f"""
ë‹¤ìŒì€ í•œ ì‚¬ìš©ìê°€ ì“´ ì¼ê¸°ì…ë‹ˆë‹¤.  
ì´ ì¼ê¸°ë¥¼ **ì˜ë¯¸ ë‹¨ìœ„**ë¡œ ë‚˜ëˆ ì„œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì²­í¬(ë©ì–´ë¦¬)ë¡œ ë§Œë“¤ì–´ ì£¼ì„¸ìš”.  

ì¡°ê±´:
- ê° ì²­í¬ëŠ” ëª…í™•í•œ ì˜ë¯¸ íë¦„ì„ ê°€ì ¸ì•¼ í•©ë‹ˆë‹¤.
- ë¬¸ì¥ì€ ìë¥´ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ëœ ë¬¸ì¥ë¼ë¦¬ ë¬¶ì–´ ì£¼ì„¸ìš”.
- ì¶œë ¥ì€ ë¦¬ìŠ¤íŠ¸(JSON ë°°ì—´) í˜•íƒœë¡œ ì£¼ì„¸ìš”.

ğŸ“œ ì¼ê¸°:
{diary_text}

ğŸ“¦ ì¶œë ¥ í˜•ì‹:
```json
[
  "ì²­í¬1",
  "ì²­í¬2"
]
```
"""
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì „ë¬¸ ì²­í¬ ë¶„ì„ê¸°ì•¼."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )
                content = response.choices[0].message.content.strip()
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                return json.loads(content)
            except Exception as e:
                print(f"âš ï¸ ì²­í¬ ë¶„í•  ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        return []
    
    def extract_emotion_situation(self, text: str, max_retries: int = 3) -> Tuple[Optional[str], Optional[str]]:
        """ê°ì •ê³¼ ìƒí™© ì¶”ì¶œ"""
        system_prompt = """ë‹¹ì‹ ì€ ì‹¬ë¦¬ ë¶„ì„ì— ëŠ¥ìˆ™í•œ AIì…ë‹ˆë‹¤.

ë‹¤ìŒì€ ì‚¬ìš©ì ì¼ê¸°ì—ì„œ ë¶„ë¦¬ëœ í•œ ê°œì˜ ì²­í¬(ë¬¸ì¥ ë¬¶ìŒ)ì…ë‹ˆë‹¤.  
ì´ ì²­í¬ì˜ ë‚´ìš© ì „ì²´ë¥¼ ì´í•´í•˜ê³ , ë‹¤ìŒ ì¡°ê±´ì— ë”°ë¼ **ì£¼ëœ ê°ì • 1ê°œì™€ ìƒí™© 1ê°œë¥¼ ì¶”ì¶œ**í•˜ì„¸ìš”.

âœ… ì¡°ê±´:
1. ê°ì •ê³¼ ìƒí™©ì€ ê°ê° **ì •í™•íˆ 1ê°œ**ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤.
2. ê°ì •ì€ ì‚¬ìš©ìì˜ ì‹¬ë¦¬ ìƒíƒœ, ì •ì„œ, ë°˜ì‘ (ì˜ˆ: ì™¸ë¡œì›€, ë¿Œë“¯í•¨, ë¶„ë…¸ ë“±)
3. ìƒí™©ì€ ì‚¬ìš©ìì˜ í–‰ë™, í™˜ê²½, ë§¥ë½ (ì˜ˆ: ë°œí‘œ, ì¹œêµ¬ì™€ ëŒ€í™” ë“±)
4. ì¶”ìƒì  ë‹¨ì–´ë‚˜ ë³µí•© ê°ì •ì€ í”¼í•˜ì„¸ìš”.
5. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ê·¸ ì™¸ ì„¤ëª…ì€ ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”.

ğŸ“¦ ì¶œë ¥ í˜•ì‹ (í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¬ ê²ƒ):

```json
{
  "ê°ì •": "ì—¬ê¸°ì— ê°ì • 1ê°œ",
  "ìƒí™©": "ì—¬ê¸°ì— ìƒí™© 1ê°œ"
}
```"""
        
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": text}
                    ],
                    temperature=0.3
                )
                content = response.choices[0].message.content.strip()
                
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                
                result = json.loads(content)
                return result.get("ê°ì •"), result.get("ìƒí™©")
            except Exception as e:
                print(f"âš ï¸ ê°ì •/ìƒí™© ì¶”ì¶œ ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        
        return None, None
    
    def map_to_categories(self, emotion: str, situation: str, max_retries: int = 3) -> Tuple[Optional[str], Optional[str]]:
        """ê°ì •ê³¼ ìƒí™©ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘"""
        prompt = f"""
ë‹¤ìŒì€ LLMì´ ì¶”ì¶œí•œ ê°ì •ê³¼ ìƒí™©ì…ë‹ˆë‹¤:
- ê°ì •: "{emotion}"
- ìƒí™©: "{situation}"

ì´ ê°ì •ê³¼ ìƒí™©ì„ ì•„ë˜ ì‚¬ì „ ì •ì˜ëœ ì¹´í…Œê³ ë¦¬ ì¤‘ ê°€ì¥ ìœ ì‚¬í•œ í•­ëª©ìœ¼ë¡œ ê°ê° ë§¤í•‘í•´ì£¼ì„¸ìš”.  
ì •í™•íˆ ì¼ì¹˜í•˜ì§€ ì•Šì•„ë„ ì˜ë¯¸ìƒ ê°€ì¥ ê°€ê¹Œìš´ í•­ëª© í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì„¸ìš”.  
ì¹´í…Œê³ ë¦¬ ì™¸ì˜ ê°’ì„ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”.

ğŸ“Œ ê°ì • ì¹´í…Œê³ ë¦¬ ëª©ë¡:
["ê¸ì •ì  ê°ì •", "ë¶€ì •ì  ê°ì •", "ë‘ë ¤ì›€ê³¼ ê³µí¬", "ë¶ˆì•ˆê³¼ ê¸´ì¥", "ìˆ˜ì¹˜ì™€ ìì±…", "ì†Œì™¸ì™€ ìƒì‹¤", "ê·¸ë¦¬ì›€ê³¼ ì•„ì‰¬ì›€", "ë™ê¸°ì™€ ìš•êµ¬", "ì‚¬íšŒì  ê´€ê³„ ê°ì •", "ì´ì™„ê³¼ ì¹¨ì²´", "í˜¼ë€ê³¼ ì˜ì‹¬", "ê²½ì´ì™€ ì••ë„"]

ğŸ“Œ ìƒí™© ì¹´í…Œê³ ë¦¬ ëª©ë¡:
["ì¼ìƒ ë° ì—¬ê°€", "ì¸ê°„ê´€ê³„", "ì—…ë¬´ ë° í•™ìŠµ", "ê±´ê°• ë° ì˜ë£Œ", "ë””ì§€í„¸ ë° ì˜¨ë¼ì¸ í™œë™", "ë‚´ë©´ í™œë™ ë° ê°ì •", "ê²½ì œ ë° ì†Œë¹„ìƒí™œ", "íŠ¹ë³„í•œ ë‚ ê³¼ ì‚¬ê±´", "ì°½ì‘ê³¼ ì„±ì¥"]

ğŸ“¦ ì¶œë ¥ í˜•ì‹:
```json
{{
  "ê°ì •ì¹´í…Œê³ ë¦¬": "ì—¬ê¸°ì— ê°ì • ì¹´í…Œê³ ë¦¬",
  "ìƒí™©ì¹´í…Œê³ ë¦¬": "ì—¬ê¸°ì— ìƒí™© ì¹´í…Œê³ ë¦¬"
}}
```"""
        
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ê°ì •ê³¼ ìƒí™©ì„ ì •í™•íˆ ì‚¬ì „ ì¹´í…Œê³ ë¦¬ì— ë§¤í•‘í•˜ëŠ” AIì•¼. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´. ê°ì •ì¹´í…Œê³ ë¦¬ì™€ ìƒí™©ì¹´í…Œê³ ë¦¬ë¼ëŠ” ì •í™•í•œ keyë¥¼ ì‚¬ìš©í•´."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.0
                )
                content = response.choices[0].message.content.strip()
                
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                
                result = json.loads(content)
                return result.get("ê°ì •ì¹´í…Œê³ ë¦¬"), result.get("ìƒí™©ì¹´í…Œê³ ë¦¬")
            except Exception as e:
                print(f"âš ï¸ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        
        return None, None
    
    def calculate_cosine_similarity_torch(self, embedding1, embedding2) -> float:
        """torchë¥¼ ì‚¬ìš©í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if isinstance(embedding1, list):
            embedding1 = np.array(embedding1)
        if isinstance(embedding2, list):
            embedding2 = np.array(embedding2)
        
        vec1 = torch.tensor(embedding1, dtype=torch.float32)
        vec2 = torch.tensor(embedding2, dtype=torch.float32)
        
        cosine_sim = F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0), dim=1)
        return cosine_sim.item()
    
    def find_similar_past_diaries(self, current_embedding: List[float], user_id: str) -> List[str]:
        """ìœ ì‚¬í•œ ê³¼ê±° ì¼ê¸° ê²€ìƒ‰"""
        today = datetime.now().strftime('%Y.%m.%d')
        similar_diaries = []
        
        try:
            similar_results = self.pre_diary_col.query(
                query_embeddings=[current_embedding],
                where={
                    "$and": [
                        {"user_id": user_id},
                        {"date": {"$ne": today}}
                    ]
                },
                n_results=3,
                include=['documents', 'embeddings']
            )
            
            if similar_results['documents'] and similar_results['documents'][0]:
                for doc, doc_embedding in zip(similar_results['documents'][0], similar_results['embeddings'][0]):
                    similarity = self.calculate_cosine_similarity_torch(current_embedding, doc_embedding)
                    if similarity >= 0.7:
                        similar_diaries.append(doc)
        except Exception as e:
            print(f"âš ï¸ ê³¼ê±° ì¼ê¸° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return similar_diaries
    
    def find_relevant_advice(self, current_embedding: List[float], emotion_category: str, situation_category: str) -> List[str]:
        """ê´€ë ¨ ì¡°ì–¸ ê²€ìƒ‰"""
        advice_list = []
        
        try:
            advice_results = self.advice_col.query(
                query_embeddings=[current_embedding],
                where={
                    "$and": [
                        {"emotion": emotion_category},
                        {"situation": situation_category}
                    ]
                },
                n_results=2,
                include=["documents", "embeddings"]
            )
            
            if advice_results.get("documents") and advice_results["documents"][0]:
                for doc, doc_embedding in zip(advice_results["documents"][0], advice_results["embeddings"][0]):
                    similarity = self.calculate_cosine_similarity_torch(current_embedding, doc_embedding)
                    if similarity >= 0.7 and doc:
                        advice_list.append(doc)
        except Exception as e:
            print(f"âš ï¸ ì¡°ì–¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return advice_list
    
    def generate_final_advice(self, advice_list: List[str]) -> Optional[str]:
        """ì¡°ì–¸ í†µí•© ë° ìµœì¢… ì¡°ì–¸ ìƒì„±"""
        if not advice_list:
            return None
        
        advice_prompt = f"""
ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì‘ì„±í•œ ì¼ê¸°ì˜ ê° ì²­í¬ì—ì„œ ì¶”ì¶œëœ ì¡°ì–¸ë“¤ì…ë‹ˆë‹¤.

ì´ ì¡°ì–¸ë“¤ì€ ìƒí™©ì— ë”°ë¼ ì¤‘ë³µë˜ê±°ë‚˜ ìœ ì‚¬í•œ ë‚´ìš©ì„ ë‹´ê³  ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì´ ì¡°ì–¸ë“¤ì„ ì¢…í•©í•´ì„œ, ì „ì²´ íë¦„ì„ ê³ ë ¤í•œ **í•µì‹¬ì ì¸ í•˜ë‚˜ì˜ ì¡°ì–¸ ë¬¸ì¥**ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”.

ì¡°ê±´:
- ë„ˆë¬´ ê¸¸ê²Œ ì“°ì§€ ë§ê³ , í•œ ë¬¸ì¥ ë˜ëŠ” ë‘ ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
- ë§íˆ¬ëŠ” ë”°ëœ»í•˜ê³  ë¶€ë“œëŸ½ê²Œ í•´ì£¼ì„¸ìš”.
- ë°˜ë³µë˜ê±°ë‚˜ ë¶ˆí•„ìš”í•œ ë‚´ìš©ì€ ì •ë¦¬í•´ì„œ í•˜ë‚˜ë¡œ í†µí•©í•´ ì£¼ì„¸ìš”.

---

ì¡°ì–¸ ë¦¬ìŠ¤íŠ¸:
{chr(10).join(f"- {a}" for a in advice_list)}

---

# ì¶œë ¥ í˜•ì‹:
```text
í•˜ë‚˜ì˜ í†µí•© ì¡°ì–¸ ë¬¸ì¥
```
"""
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì‹¬ë¦¬ ìƒë‹´ ì „ë¬¸ê°€ì•¼. ì—¬ëŸ¬ ì¡°ì–¸ì„ í•˜ë‚˜ë¡œ ë”°ëœ»í•˜ê²Œ í†µí•©í•´ì¤˜."},
                    {"role": "user", "content": advice_prompt}
                ],
                temperature=0.4
            )
            advice = response.choices[0].message.content.strip().strip("```text").strip("```").strip()
            return advice
        except Exception as e:
            print(f"âŒ í†µí•© ì¡°ì–¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def find_relevant_quote(self, advice: str) -> Optional[str]:
        """ê´€ë ¨ ì¸ìš©ë¬¸ ê²€ìƒ‰"""
        if not advice:
            return None
        
        try:
            advice_emb = self.general_embedding_function([advice])[0]
            quote_results = self.quote_col.query(
                query_embeddings=[advice_emb], 
                n_results=3, 
                include=["documents", "distances", "metadatas"]
            )
            
            best_quote = None
            best_similarity = -1
            
            for doc, dist, meta in zip(
                quote_results.get("documents", [[]])[0],
                quote_results.get("distances", [[]])[0],
                quote_results.get("metadatas", [[]])[0]
            ):
                cosine_similarity = 1 - dist
                msg = meta.get("message", doc)
                author = meta.get("author", "")
                
                if cosine_similarity > best_similarity and cosine_similarity >= 0.65:
                    if author:
                        quote_str = f'"{msg}" - {author}'
                    else:
                        quote_str = f'"{msg}"'
                    best_quote = quote_str
            
            return best_quote
        except Exception as e:
            print(f"âš ï¸ ì¸ìš©ë¬¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def generate_comment(self, current_diary: str, advice: str, similar_past_diaries: List[str], quote: Optional[str]) -> str:
        """AI ì½”ë©˜íŠ¸ ìƒì„±"""
        generator = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7, n=3)
        
        system_prompt = "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê°ì •ì„ ì§„ì‹¬ìœ¼ë¡œ ì´í•´í•˜ê³  ìœ„ë¡œí•´ì£¼ëŠ” ë”°ëœ»í•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤."
        
        if quote:
            human_prompt = f"""ì•„ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§„ì‹¬ ì–´ë¦° ê³µê°ê³¼ ê²©ë ¤ì˜ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¼ê¸°:
{current_diary}

ì¡°ì–¸:
{advice}

{f'\nê³¼ê±° ìœ ì‚¬ ì¼ê¸° ê¸°ë¡:\n{similar_past_diaries}' if similar_past_diaries else ''}
{f'\nê´€ë ¨ ì¸ìš©ë¬¸:\n{quote}'}

ìš”êµ¬ì‚¬í•­:
- ì½”ë©˜íŠ¸ëŠ” 3~4ë¬¸ì¥ìœ¼ë¡œ í•˜ë‚˜ì˜ ë¬¸ë‹¨ì„ ì´ë£¨ì–´ì•¼ í•©ë‹ˆë‹¤.
- ë°˜ë“œì‹œ ì¡°ì–¸ ë‚´ìš©ì„ ì°¸ê³ í•˜ë˜, ì½”ë©˜íŠ¸ì— 'ì¡°ì–¸ì— ë”°ë¼', 'ì¡°ì–¸ì„ ì°¸ê³ í•˜ì—¬' ë“± ì¡°ì–¸ì„ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
- ê³¼ê±° ì¼ê¸° ê¸°ë¡ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
- ê´€ë ¨ ì¸ìš©ë¬¸ì„ ë”°ì˜´í‘œ("")ë¡œ ê°ì‹¸ê³  ì €ìì™€ í•¨ê»˜ í‘œì‹œí•´ì£¼ì„¸ìš”.
- ë”°ëœ»í•˜ê³  ê³µê° ì–´ë¦° ë§íˆ¬ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”."""
        else:
            human_prompt = f"""ì•„ë˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì§„ì‹¬ ì–´ë¦° ê³µê°ê³¼ ê²©ë ¤ì˜ ì½”ë©˜íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ì¼ê¸°:
{current_diary}

ì¡°ì–¸:
{advice}

{f'\nê³¼ê±° ìœ ì‚¬ ì¼ê¸° ê¸°ë¡:\n{similar_past_diaries}' if similar_past_diaries else ''}

ìš”êµ¬ì‚¬í•­:
- ì½”ë©˜íŠ¸ëŠ” 3~4ë¬¸ì¥ìœ¼ë¡œ í•˜ë‚˜ì˜ ë¬¸ë‹¨ì„ ì´ë£¨ì–´ì•¼ í•©ë‹ˆë‹¤.
- ë°˜ë“œì‹œ ì¡°ì–¸ ë‚´ìš©ì„ ì°¸ê³ í•˜ë˜, ì½”ë©˜íŠ¸ì— 'ì¡°ì–¸ì— ë”°ë¼', 'ì¡°ì–¸ì„ ì°¸ê³ í•˜ì—¬' ë“± ì¡°ì–¸ì„ ì§ì ‘ì ìœ¼ë¡œ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”.
- ê³¼ê±° ì¼ê¸° ê¸°ë¡ì´ ìˆëŠ” ê²½ìš° í•´ë‹¹ ë‚´ìš©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì–¸ê¸‰í•´ì£¼ì„¸ìš”.
- ë”°ëœ»í•˜ê³  ê³µê° ì–´ë¦° ë§íˆ¬ë¥¼ ìœ ì§€í•´ì£¼ì„¸ìš”."""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        response = generator.generate([messages])
        comments = [gen.text.strip() for gen in response.generations[0]]
        
        # ìµœì¢… ì½”ë©˜íŠ¸ ì„ íƒ
        selector = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, n=1)
        
        select_system = SystemMessage(content="ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ê°ê´€ì ì¸ í‰ê°€ìì…ë‹ˆë‹¤.")
        select_human = HumanMessage(content=f"""ìœ„ì— ìƒì„±ëœ ì„¸ ê°œì˜ ì½”ë©˜íŠ¸ ì¤‘ì—ì„œ
"ì¼ê¸°ì˜ ê°ì •ê³¼ ìƒí™©, ì œì‹œëœ ì¡°ì–¸, ê³¼ê±° ìœ ì‚¬ ì¼ê¸°, ê·¸ë¦¬ê³  ì¸ìš©ë¬¸"ì„
ê°€ì¥ ì˜ ë°˜ì˜í•œ í•œ ê°€ì§€ ì½”ë©˜íŠ¸ë¥¼ ê³¨ë¼ì„œ, ë²ˆí˜¸ì™€ í•¨ê»˜ í•´ë‹¹ ì½”ë©˜íŠ¸ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”.

1) {comments[0]}

2) {comments[1]}

3) {comments[2]}""")
        
        selection = selector.invoke([select_system, select_human])
        final_comment = selection.content.strip()
        
        # ë²ˆí˜¸ ì œê±°
        if final_comment and any(final_comment.startswith(f"{i})") for i in range(1, 4)):
            for i in range(1, 4):
                if final_comment.startswith(f"{i})"):
                    final_comment = final_comment[len(f"{i})"):].strip()
                    break
        
        return final_comment
    
    def extract_emotion_keywords(self, chunks: List[str]) -> List[str]:
        """ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not chunks:
            return []
        
        prompt = f"""
ë‹¤ìŒì€ ì‚¬ìš©ìê°€ ì‘ì„±í•œ ì¼ê¸°ì˜ ì²­í¬ë“¤ì…ë‹ˆë‹¤. 
ì´ ë‚´ìš©ì—ì„œ ë‚˜íƒ€ë‚˜ëŠ” ì£¼ìš” ê°ì • í‚¤ì›Œë“œë“¤ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì¼ê¸° ì²­í¬ë“¤:
{chr(10).join(f"- {chunk}" for chunk in chunks)}

ê°ì • í‚¤ì›Œë“œë“¤ì„ ì‰¼í‘œë¡œ êµ¬ë¶„í•˜ì—¬ ì¶œë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: ê¸°ì¨, í‰ì˜¨, ëŒ€ê²¬í•¨, ì¼ìƒ)
"""
        
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì¼ê¸°ì—ì„œ ê°ì • í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            keywords = response.choices[0].message.content.strip()
            return [kw.strip() for kw in keywords.split(',')]
        except Exception as e:
            print(f"âš ï¸ ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    async def analyze_diary(self, user_id: str, raw_diary: str) -> DiaryAnalysisResponse:
        """ì¼ê¸° ë¶„ì„ ë° ì½”ë©˜íŠ¸ ìƒì„± ë©”ì¸ í•¨ìˆ˜"""
        # 1. ì¼ê¸° ì „ì²˜ë¦¬
        processed_diary = self.preprocess_diary(raw_diary)
        
        # 2. ì˜ë¯¸ ë‹¨ìœ„ ì²­í¬ ë¶„í• 
        chunks = self.chunk_diary_by_meaning(processed_diary)
        
        # 3. ê° ì²­í¬ë³„ ê°ì •/ìƒí™© ë¶„ì„ ë° ì¡°ì–¸ ìˆ˜ì§‘
        advice_list = []
        similar_past_diaries = []
        
        for i, chunk in enumerate(chunks):
            # ê°ì •/ìƒí™© ì¶”ì¶œ
            emotion, situation = self.extract_emotion_situation(chunk)
            
            if emotion and situation:
                # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
                emotion_category, situation_category = self.map_to_categories(emotion, situation)
                
                if emotion_category and situation_category:
                    # í˜„ì¬ ì²­í¬ ì„ë² ë”© ìƒì„±
                    current_embedding_diary = self.diary_embedding_function([chunk])[0]
                    current_embedding = self.general_embedding_function([chunk])[0]
                    
                    # ìœ ì‚¬í•œ ê³¼ê±° ì¼ê¸° ê²€ìƒ‰
                    similar_diaries = self.find_similar_past_diaries(current_embedding_diary, user_id)
                    similar_past_diaries.extend(similar_diaries)
                    
                    # ì¼ê¸° ì €ì¥
                    chunk_id = f"{user_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}_{i}"
                    today = datetime.now().strftime('%Y.%m.%d')
                    self.pre_diary_col.add(
                        documents=[chunk],
                        metadatas=[{
                            "user_id": user_id,
                            "date": today,
                            "emotion": emotion_category,
                            "situation": situation_category
                        }],
                        ids=[chunk_id]
                    )
                    
                    # ê´€ë ¨ ì¡°ì–¸ ê²€ìƒ‰
                    chunk_advice_list = self.find_relevant_advice(current_embedding, emotion_category, situation_category)
                    advice_list.extend(chunk_advice_list)
        
        # 4. ìµœì¢… ì¡°ì–¸ ìƒì„±
        final_advice = self.generate_final_advice(advice_list)
        
        # 5. ê´€ë ¨ ì¸ìš©ë¬¸ ê²€ìƒ‰
        quote = self.find_relevant_quote(final_advice) if final_advice else None
        
        # 6. AI ì½”ë©˜íŠ¸ ìƒì„±
        comment = self.generate_comment(processed_diary, final_advice or "", similar_past_diaries, quote)
        
        # 7. ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        emotion_keywords = self.extract_emotion_keywords(chunks)
        
        return DiaryAnalysisResponse(
            processed_diary=processed_diary,
            chunks=chunks,
            advice=final_advice,
            comment=comment,
            quote=quote,
            emotion_keywords=emotion_keywords,
            similar_past_diaries=similar_past_diaries
        ) 