import os
import json
import time
from datetime import datetime
from typing import List, Optional, Tuple

import openai
from dotenv import load_dotenv
import chromadb
from transformers import AutoTokenizer, AutoModel
import torch
import torch.nn.functional as F
import numpy as np
from langchain_community.chat_models import ChatOpenAI
from langchain.schema import SystemMessage, HumanMessage

from app.models.diary import DiaryAnalysisResponse, DiaryChunk, EmotionSituationExtraction
from app.prompts.loader import load_prompt

# í™˜ê²½ì„¤ì •
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

class DiaryAnalyzer:
    """ì¼ê¸° ë¶„ì„ ë° ì½”ë©˜íŠ¸ ìƒì„± ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # HuggingFace ëª¨ë¸ ë¡œë”© (vector_db.pyì™€ ë™ì¼í•œ ë°©ì‹)
        self.tokenizer_diary = AutoTokenizer.from_pretrained("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
        self.embedding_model_diary = AutoModel.from_pretrained("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
        
        self.tokenizer_general = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
        self.embedding_model_general = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
        
        # ChromaDB ì„¤ì • (ì„ë² ë”© í•¨ìˆ˜ ì—†ì´)
        self.client = chromadb.PersistentClient(path="./data/chroma_db")
        self.pre_diary_col = self.client.get_or_create_collection(name="diary_past_diaries")
        self.advice_col = self.client.get_or_create_collection(name="diary_advice")
        self.quote_col = self.client.get_or_create_collection(name="diary_quotes")
    
    def embed_text_diary(self, text: str) -> List[float]:
        """ì¼ê¸° í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Mean Pooling ë°©ì‹)"""
        try:
            # 1. í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜
            encoded_input = self.tokenizer_diary(text, padding=True, truncation=True, max_length=512, return_tensors='pt')
            
            # 2. AI ëª¨ë¸ì— í† í° ì…ë ¥í•´ì„œ ë²¡í„° ìƒì„±
            with torch.no_grad():
                model_output = self.embedding_model_diary(**encoded_input)
            
            # 3. Mean Pooling ì‚¬ìš© (ëª¨ë“  í† í°ì˜ í‰ê· )
            attention_mask = encoded_input['attention_mask']
            token_embeddings = model_output.last_hidden_state
            
            # íŒ¨ë”© í† í° ì œì™¸í•˜ê³  í‰ê·  ê³„ì‚°
            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
            sentence_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)
            
            # 4. ë²¡í„° ì •ê·œí™” (í¬ê¸°ë¥¼ 1ë¡œ ë§Œë“¦)
            sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)
            
            # 5. PyTorch í…ì„œë¥¼ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì„œ ë°˜í™˜
            return sentence_embeddings.squeeze().cpu().numpy().tolist()
            
        except Exception as e:
            print(f"ì¼ê¸° ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def embed_text_general(self, text: str) -> List[float]:
        """ì¼ë°˜ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (Mean Pooling ë°©ì‹)"""
        try:
            # 1. í…ìŠ¤íŠ¸ë¥¼ í† í°ìœ¼ë¡œ ë³€í™˜
            encoded_input = self.tokenizer_general(text, padding=True, truncation=True, max_length=256, return_tensors='pt')
            
            # 2. AI ëª¨ë¸ì— í† í° ì…ë ¥í•´ì„œ ë²¡í„° ìƒì„±
            with torch.no_grad():
                model_output = self.embedding_model_general(**encoded_input)
            
            # 3. Mean Pooling ì‚¬ìš© (ëª¨ë“  í† í°ì˜ í‰ê· )
            attention_mask = encoded_input['attention_mask']
            token_embeddings = model_output.last_hidden_state
            
            # íŒ¨ë”© í† í° ì œì™¸í•˜ê³  í‰ê·  ê³„ì‚°
            input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()
            sentence_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)
            
            # 4. ë²¡í„° ì •ê·œí™” (í¬ê¸°ë¥¼ 1ë¡œ ë§Œë“¦)
            sentence_embeddings = torch.nn.functional.normalize(sentence_embeddings, p=2, dim=1)
            
            # 5. PyTorch í…ì„œë¥¼ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•´ì„œ ë°˜í™˜
            return sentence_embeddings.squeeze().cpu().numpy().tolist()
            
        except Exception as e:
            print(f"ì¼ë°˜ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            raise
    
    def preprocess_diary(self, raw_diary: str, max_retries: int = 3) -> str:
        """ì¼ê¸° ì „ì²˜ë¦¬ - ë¬¸ë²• ë° ë¬¸ë§¥ ì •ë¦¬"""
        prompt = load_prompt("diary_preprocess").format(raw_diary=raw_diary)
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ë¬¸ì¥ êµì •ì— íŠ¹í™”ëœ í•œêµ­ì–´ í¸ì§‘ê¸°ì•¼. ì¼ê¸°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ê³ ì³ì¤˜."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )
                content = response.choices[0].message.content.strip()
                if "```" in content:
                    content = content.split("```")[1].strip()
                return content
            except Exception as e:
                print(f"âš ï¸ ì¼ê¸° ì „ì²˜ë¦¬ ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        return raw_diary
    
    def chunk_diary_by_meaning(self, diary_text: str, max_retries: int = 3) -> List[str]:
        """ì˜ë¯¸ ë‹¨ìœ„ë¡œ ì¼ê¸° ì²­í¬ ë¶„í• """
        prompt = load_prompt("diary_chunking").format(diary_text=diary_text)
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì „ë¬¸ ì²­í¬ ë¶„ì„ê¸°ì•¼. ì¤„ë°”ê¿ˆì´ë‚˜ ë¶ˆí•„ìš”í•œ ê³µë°± ì—†ì´ ê¹”ë”í•œ JSONë§Œ ì¶œë ¥í•´."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.3
                )
                content = response.choices[0].message.content.strip()
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()
                
                # ëª¨ë“  ì¤„ë°”ê¿ˆê³¼ ê³µë°± ì •ë¦¬
                content = content.replace('\n', '').replace('\r', '').replace('  ', ' ').strip()
                
                # JSON íŒŒì‹± ì „ì— ì¶”ê°€ ê²€ì¦
                if not content.startswith('[') or not content.endswith(']'):
                    print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ JSON ë°°ì—´ í˜•ì‹: {content}")
                    time.sleep(1)
                    continue
                
                return json.loads(content)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                print(f"ğŸ“ ë¬¸ì œê°€ ëœ ë‚´ìš©: {content}")
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë” ê°•ë ¥í•œ ì •ë¦¬ ì‹œë„
                try:
                    # ëŒ€ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
                    start = content.find('[')
                    end = content.rfind(']')
                    if start != -1 and end != -1:
                        content = content[start:end+1]
                        return json.loads(content)
                except:
                    pass
                time.sleep(1)
            except Exception as e:
                print(f"âš ï¸ ì²­í¬ ë¶„í•  ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        return []
    
    def extract_emotion_situation(self, text: str, max_retries: int = 3) -> Tuple[Optional[str], Optional[str]]:
        """ê°ì •ê³¼ ìƒí™© ì¶”ì¶œ"""
        system_prompt = load_prompt("emotion_situation_extraction")
        
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": system_prompt + " ì¤„ë°”ê¿ˆì´ë‚˜ ë¶ˆí•„ìš”í•œ ê³µë°± ì—†ì´ ê¹”ë”í•œ JSONë§Œ ì¶œë ¥í•´."},
                        {"role": "user", "content": text}
                    ],
                    temperature=0.3
                )
                content = response.choices[0].message.content.strip()
                
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()
                
                # ëª¨ë“  ì¤„ë°”ê¿ˆê³¼ ê³µë°± ì •ë¦¬
                content = content.replace('\n', '').replace('\r', '').replace('  ', ' ').strip()
                
                # JSON íŒŒì‹± ì „ì— ì¶”ê°€ ê²€ì¦
                if not content.startswith('{') or not content.endswith('}'):
                    print(f"âš ï¸ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹: {content}")
                    time.sleep(1)
                    continue
                
                result = json.loads(content)
                return result.get("ê°ì •"), result.get("ìƒí™©")
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                print(f"ğŸ“ ë¬¸ì œê°€ ëœ ë‚´ìš©: {content}")
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë” ê°•ë ¥í•œ ì •ë¦¬ ì‹œë„
                try:
                    # ì¤‘ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
                    start = content.find('{')
                    end = content.rfind('}')
                    if start != -1 and end != -1:
                        content = content[start:end+1]
                        result = json.loads(content)
                        return result.get("ê°ì •"), result.get("ìƒí™©")
                except:
                    pass
                time.sleep(1)
            except Exception as e:
                print(f"âš ï¸ ê°ì •/ìƒí™© ì¶”ì¶œ ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        
        return None, None
    
    def map_to_categories(self, emotion: str, situation: str, max_retries: int = 3) -> Tuple[Optional[str], Optional[str]]:
        """ê°ì •ê³¼ ìƒí™©ì„ ì¹´í…Œê³ ë¦¬ë¡œ ë§¤í•‘"""
        prompt = load_prompt("category_mapping").format(emotion=emotion, situation=situation)
        
        for attempt in range(max_retries):
            try:
                response = openai.chat.completions.create(
                    model="gpt-4o",
                    messages=[
                        {"role": "system", "content": "ë„ˆëŠ” ê°ì •ê³¼ ìƒí™©ì„ ì •í™•íˆ ì‚¬ì „ ì¹´í…Œê³ ë¦¬ì— ë§¤í•‘í•˜ëŠ” AIì•¼. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•´. ê°ì •ì¹´í…Œê³ ë¦¬ì™€ ìƒí™©ì¹´í…Œê³ ë¦¬ë¼ëŠ” ì •í™•í•œ keyë¥¼ ì‚¬ìš©í•´. ì¤„ë°”ê¿ˆì´ë‚˜ ë¶ˆí•„ìš”í•œ ê³µë°± ì—†ì´ ê¹”ë”í•œ JSONë§Œ ì¶œë ¥í•´."},
                        {"role": "user", "content": prompt}
                    ],
                    temperature=0.0
                )
                content = response.choices[0].message.content.strip()
                
                # JSON ì½”ë“œ ë¸”ë¡ ì œê±°
                if "```json" in content:
                    content = content.split("```json")[1].split("```")[0].strip()
                elif "```" in content:
                    content = content.split("```")[1].split("```")[0].strip()
                
                # ëª¨ë“  ì¤„ë°”ê¿ˆê³¼ ê³µë°± ì •ë¦¬
                content = content.replace('\n', '').replace('\r', '').replace('  ', ' ').strip()
                
                # ë””ë²„ê¹…ì„ ìœ„í•œ ë¡œê·¸ ì¶”ê°€
                print(f"       ğŸ” GPT ì‘ë‹µ ì›ë³¸: {content}")
                
                # JSON íŒŒì‹± ì „ì— ì¶”ê°€ ê²€ì¦
                if not content.startswith('{') or not content.endswith('}'):
                    print(f"       âŒ ìœ íš¨í•˜ì§€ ì•Šì€ JSON í˜•ì‹: {content}")
                    time.sleep(1)
                    continue
                
                result = json.loads(content)
                emotion_category = result.get("ê°ì •ì¹´í…Œê³ ë¦¬")
                situation_category = result.get("ìƒí™©ì¹´í…Œê³ ë¦¬")
                
                print(f"       âœ… íŒŒì‹± ì„±ê³µ - ê°ì •: {emotion_category}, ìƒí™©: {situation_category}")
                return emotion_category, situation_category
                
            except json.JSONDecodeError as e:
                print(f"       âŒ JSON íŒŒì‹± ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                print(f"       ğŸ“ ë¬¸ì œê°€ ëœ ë‚´ìš©: {content}")
                # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë” ê°•ë ¥í•œ ì •ë¦¬ ì‹œë„
                try:
                    # ì¤‘ê´„í˜¸ ì•ˆì˜ ë‚´ìš©ë§Œ ì¶”ì¶œ
                    start = content.find('{')
                    end = content.rfind('}')
                    if start != -1 and end != -1:
                        content = content[start:end+1]
                        result = json.loads(content)
                        emotion_category = result.get("ê°ì •ì¹´í…Œê³ ë¦¬")
                        situation_category = result.get("ìƒí™©ì¹´í…Œê³ ë¦¬")
                        print(f"       âœ… ì¬ì‹œë„ íŒŒì‹± ì„±ê³µ - ê°ì •: {emotion_category}, ìƒí™©: {situation_category}")
                        return emotion_category, situation_category
                except:
                    pass
                time.sleep(1)
            except Exception as e:
                print(f"       âš ï¸ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì‹¤íŒ¨ {attempt+1}íšŒ: {e}")
                time.sleep(1)
        
        print(f"       âŒ ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼")
        return None, None
    
    def calculate_cosine_similarity_torch(self, embedding1, embedding2) -> float:
        """torchë¥¼ ì‚¬ìš©í•œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        if isinstance(embedding1, list):
            embedding1 = np.array(embedding1)
        if isinstance(embedding2, list):
            embedding2 = np.array(embedding2)
        
        vec1 = torch.tensor(embedding1, dtype=torch.float32)
        vec2 = torch.tensor(embedding2, dtype=torch.float32)
        
        cosine_sim = F.cosine_similarity(vec1.unsqueeze(0), vec2.unsqueeze(0), dim=1)
        return cosine_sim.item()
    
    def find_similar_past_diaries(self, current_embedding: List[float], user_id: str) -> List[str]:
        """ìœ ì‚¬í•œ ê³¼ê±° ì¼ê¸° ê²€ìƒ‰"""
        today = datetime.now().strftime('%Y.%m.%d')
        similar_diaries = []
        
        try:
            print(f"       ğŸ” ê³¼ê±° ì¼ê¸° ê²€ìƒ‰ (ì‚¬ìš©ì: {user_id}, ì œì™¸ ë‚ ì§œ: {today})")
            similar_results = self.pre_diary_col.query(
                query_embeddings=[current_embedding],
                where={
                    "$and": [
                        {"user_id": user_id},
                        {"date": {"$ne": today}}
                    ]
                },
                n_results=3,
                include=['documents', 'embeddings']
            )
            
            if similar_results['documents'] and similar_results['documents'][0]:
                print(f"       ğŸ“Š ê²€ìƒ‰ëœ í›„ë³´: {len(similar_results['documents'][0])}ê°œ")
                for i, (doc, doc_embedding) in enumerate(zip(similar_results['documents'][0], similar_results['embeddings'][0])):
                    similarity = self.calculate_cosine_similarity_torch(current_embedding, doc_embedding)
                    print(f"         í›„ë³´ {i+1} ìœ ì‚¬ë„: {similarity:.3f}")
                    if similarity >= 0.7:
                        similar_diaries.append(doc)
                        print(f"         âœ… ìœ ì‚¬ë„ {similarity:.3f}ë¡œ ì„ íƒë¨")
                    else:
                        print(f"         âŒ ìœ ì‚¬ë„ {similarity:.3f}ë¡œ ì œì™¸ë¨")
                print(f"       ğŸ“ ìµœì¢… ì„ íƒëœ ê³¼ê±° ì¼ê¸°: {len(similar_diaries)}ê°œ")
            else:
                print(f"       âš ï¸ ì‚¬ìš©ì ê³¼ê±° ì¼ê¸° ì—†ìŒ")
        except Exception as e:
            print(f"       âŒ ê³¼ê±° ì¼ê¸° ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return similar_diaries
    
    def find_relevant_advice(self, current_embedding: List[float], emotion_category: str, situation_category: str) -> List[str]:
        """ê´€ë ¨ ì¡°ì–¸ ê²€ìƒ‰"""
        advice_list = []
        
        try:
            print(f"       ğŸ’¡ ì¡°ì–¸ ê²€ìƒ‰ (ê°ì •: {emotion_category}, ìƒí™©: {situation_category})")
            advice_results = self.advice_col.query(
                query_embeddings=[current_embedding],
                where={
                    "$and": [
                        {"emotion": emotion_category},
                        {"situation": situation_category}
                    ]
                },
                n_results=2,
                include=["documents", "embeddings"]
            )
            
            if advice_results.get("documents") and advice_results["documents"][0]:
                print(f"       ğŸ“Š ê²€ìƒ‰ëœ ì¡°ì–¸ í›„ë³´: {len(advice_results['documents'][0])}ê°œ")
                for i, (doc, doc_embedding) in enumerate(zip(advice_results["documents"][0], advice_results["embeddings"][0])):
                    similarity = self.calculate_cosine_similarity_torch(current_embedding, doc_embedding)
                    print(f"         ì¡°ì–¸ {i+1} ìœ ì‚¬ë„: {similarity:.3f}")
                    if similarity >= 0.7 and doc:
                        advice_list.append(doc)
                        print(f"         âœ… ìœ ì‚¬ë„ {similarity:.3f}ë¡œ ì„ íƒë¨")
                    else:
                        print(f"         âŒ ìœ ì‚¬ë„ {similarity:.3f}ë¡œ ì œì™¸ë¨")
                print(f"       ğŸ“ ìµœì¢… ì„ íƒëœ ì¡°ì–¸: {len(advice_list)}ê°œ")
            else:
                print(f"       âš ï¸ í•„í„° ì¡°ê±´ì— ë§ëŠ” ì¡°ì–¸ ì—†ìŒ")
        except Exception as e:
            print(f"       âŒ ì¡°ì–¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        return advice_list
    
    def generate_final_advice(self, advice_list: List[str]) -> Optional[str]:
        """ì¡°ì–¸ í†µí•© ë° ìµœì¢… ì¡°ì–¸ ìƒì„±"""
        if not advice_list:
            print("       âš ï¸ í†µí•©í•  ì¡°ì–¸ì´ ì—†ìŒ")
            return None
        
        print(f"       ğŸ”„ {len(advice_list)}ê°œ ì¡°ì–¸ í†µí•© ì‹œì‘")
        advice_list_formatted = "\n".join(f"- {a}" for a in advice_list)
        advice_prompt = load_prompt("advice_integration").format(advice_list_formatted=advice_list_formatted)
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ì‹¬ë¦¬ ìƒë‹´ ì „ë¬¸ê°€ì•¼. ì—¬ëŸ¬ ì¡°ì–¸ì„ í•˜ë‚˜ë¡œ ë”°ëœ»í•˜ê²Œ í†µí•©í•´ì¤˜."},
                    {"role": "user", "content": advice_prompt}
                ],
                temperature=0.4
            )
            advice = response.choices[0].message.content.strip().strip("```text").strip("```").strip()
            print(f"       âœ… í†µí•© ì¡°ì–¸ ìƒì„± ì™„ë£Œ")
            return advice
        except Exception as e:
            print(f"       âŒ í†µí•© ì¡°ì–¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def find_relevant_quote(self, advice: str) -> Optional[str]:
        """ê´€ë ¨ ì¸ìš©ë¬¸ ê²€ìƒ‰"""
        if not advice:
            print("       âš ï¸ ì¡°ì–¸ì´ ì—†ì–´ì„œ ëª…ì–¸ ê²€ìƒ‰ ë¶ˆê°€")
            return None
        
        try:
            print(f"       ğŸ’¬ ëª…ì–¸ ê²€ìƒ‰ ì‹œì‘")
            advice_emb = self.embed_text_general(advice)
            quote_results = self.quote_col.query(
                query_embeddings=[advice_emb], 
                n_results=3, 
                include=["documents", "distances", "metadatas"]
            )
            
            print(f"       ğŸ“Š ê²€ìƒ‰ëœ ëª…ì–¸ í›„ë³´: {len(quote_results.get('documents', [[]])[0])}ê°œ")
            best_quote = None
            best_similarity = -1
            
            for i, (doc, dist, meta) in enumerate(zip(
                quote_results.get("documents", [[]])[0],
                quote_results.get("distances", [[]])[0],
                quote_results.get("metadatas", [[]])[0]
            )):
                cosine_similarity = 1 - dist
                msg = meta.get("message", doc)
                author = meta.get("author", "")
                
                print(f"         ëª…ì–¸ {i+1} ìœ ì‚¬ë„: {cosine_similarity:.3f}")
                if cosine_similarity > best_similarity and cosine_similarity >= 0.65:
                    if author:
                        quote_str = f'"{msg}" - {author}'
                    else:
                        quote_str = f'"{msg}"'
                    best_quote = quote_str
                    best_similarity = cosine_similarity
                    print(f"         âœ… ìœ ì‚¬ë„ {cosine_similarity:.3f}ë¡œ ì„ íƒë¨")
                else:
                    print(f"         âŒ ìœ ì‚¬ë„ {cosine_similarity:.3f}ë¡œ ì œì™¸ë¨")
            
            if best_quote:
                print(f"       ğŸ“ ìµœì¢… ì„ íƒëœ ëª…ì–¸: {best_quote[:50]}...")
            else:
                print(f"       âš ï¸ ì ì ˆí•œ ëª…ì–¸ ì—†ìŒ")
            
            return best_quote
        except Exception as e:
            print(f"       âŒ ëª…ì–¸ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def generate_comment(self, current_diary: str, advice: str, similar_past_diaries: List[str], quote: Optional[str]) -> str:
        """AI ì½”ë©˜íŠ¸ ìƒì„±"""
        print(f"       ğŸ¤– AI ì½”ë©˜íŠ¸ ìƒì„± ì‹œì‘")
        print(f"         ì¼ê¸° ê¸¸ì´: {len(current_diary)}ì")
        print(f"         ì¡°ì–¸: {advice[:50]}..." if advice else "         ì¡°ì–¸: ì—†ìŒ")
        print(f"         ê³¼ê±° ì¼ê¸°: {len(similar_past_diaries)}ê°œ")
        print(f"         ëª…ì–¸: {quote[:50] if quote else 'ì—†ìŒ'}...")
        
        generator = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.7, n=3)
        
        system_prompt = "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ê°ì •ì„ ì§„ì‹¬ìœ¼ë¡œ ì´í•´í•˜ê³  ìœ„ë¡œí•´ì£¼ëŠ” ë”°ëœ»í•œ ì„ ìƒë‹˜ì…ë‹ˆë‹¤."
        
        if quote:
            similar_past_diaries_section = f'\nê³¼ê±° ìœ ì‚¬ ì¼ê¸° ê¸°ë¡:\n{similar_past_diaries}' if similar_past_diaries else ''
            quote_section = f'\nê´€ë ¨ ì¸ìš©ë¬¸:\n{quote}'
            human_prompt = load_prompt("comment_generation").format(
                current_diary=current_diary,
                advice=advice,
                similar_past_diaries_section=similar_past_diaries_section,
                quote_section=quote_section
            )
        else:
            similar_past_diaries_section = f'\nê³¼ê±° ìœ ì‚¬ ì¼ê¸° ê¸°ë¡:\n{similar_past_diaries}' if similar_past_diaries else ''
            human_prompt = load_prompt("comment_generation_no_quote").format(
                current_diary=current_diary,
                advice=advice,
                similar_past_diaries_section=similar_past_diaries_section
            )
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=human_prompt)
        ]
        
        print(f"         ğŸ”„ 3ê°œ ì½”ë©˜íŠ¸ ìƒì„± ì¤‘...")
        response = generator.generate([messages])
        comments = [gen.text.strip() for gen in response.generations[0]]
        
        print(f"         ğŸ“ ìƒì„±ëœ ì½”ë©˜íŠ¸ë“¤:")
        for i, comment in enumerate(comments, 1):
            print(f"           {i}. {comment[:100]}...")
        
        # ìµœì¢… ì½”ë©˜íŠ¸ ì„ íƒ
        print(f"         ğŸ¯ ìµœì¢… ì½”ë©˜íŠ¸ ì„ íƒ ì¤‘...")
        selector = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0, n=1)
        
        select_system = SystemMessage(content="ë‹¹ì‹ ì€ ê³µì •í•˜ê³  ê°ê´€ì ì¸ í‰ê°€ìì…ë‹ˆë‹¤.")
        select_human = HumanMessage(content=load_prompt("comment_selection").format(
            comment1=comments[0],
            comment2=comments[1],
            comment3=comments[2]
        ))
        
        selection = selector.invoke([select_system, select_human])
        final_comment = selection.content.strip()
        
        print(f"         ğŸ“Š ì„ íƒ ê²°ê³¼: {final_comment}")
        
        # ë²ˆí˜¸ ì œê±°
        if final_comment and any(final_comment.startswith(f"{i})") for i in range(1, 4)):
            for i in range(1, 4):
                if final_comment.startswith(f"{i})"):
                    final_comment = final_comment[len(f"{i})"):].strip()
                    print(f"         âœ… ìµœì¢… ì„ íƒëœ ì½”ë©˜íŠ¸: {i}ë²ˆ")
                    break
        
        return final_comment
    
    def extract_emotion_keywords(self, chunks: List[str]) -> List[str]:
        """ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if not chunks:
            return []
        
        chunks_formatted = "\n".join(f"- {chunk}" for chunk in chunks)
        prompt = load_prompt("emotion_keywords").format(chunks_formatted=chunks_formatted)
        
        try:
            response = openai.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {"role": "system", "content": "ë„ˆëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì•¼. ì¼ê¸°ì—ì„œ ê°ì • í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•´ì¤˜."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3
            )
            keywords = response.choices[0].message.content.strip()
            return [kw.strip() for kw in keywords.split(',')]
        except Exception as e:
            print(f"âš ï¸ ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []
    
    async def analyze_diary(self, user_id: str, raw_diary: str) -> DiaryAnalysisResponse:
        """ì¼ê¸° ë¶„ì„ ë° ì½”ë©˜íŠ¸ ìƒì„± ë©”ì¸ í•¨ìˆ˜"""
        print("\n" + "="*80)
        print("ğŸ“ ì¼ê¸° ë¶„ì„ ì‹œì‘")
        print("="*80)
        
        # 1. ì¼ê¸° ì „ì²˜ë¦¬
        print("\nğŸ”§ 1ë‹¨ê³„: ì¼ê¸° ì „ì²˜ë¦¬")
        processed_diary = self.preprocess_diary(raw_diary)
        print(f"   ì›ë³¸ ì¼ê¸° ê¸¸ì´: {len(raw_diary)}ì")
        print(f"   ì „ì²˜ë¦¬ í›„ ê¸¸ì´: {len(processed_diary)}ì")
        print(f"   ì „ì²˜ë¦¬ëœ ì¼ê¸°: {processed_diary[:100]}...")
        
        # 2. ì˜ë¯¸ ë‹¨ìœ„ ì²­í¬ ë¶„í• 
        print("\nğŸ“„ 2ë‹¨ê³„: ì˜ë¯¸ ë‹¨ìœ„ ì²­í¬ ë¶„í• ")
        chunks = self.chunk_diary_by_meaning(processed_diary)
        print(f"   ì´ ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")
        for i, chunk in enumerate(chunks, 1):
            print(f"   ì²­í¬ {i}: {chunk[:80]}...")
        
        # 3. ê° ì²­í¬ë³„ ê°ì •/ìƒí™© ë¶„ì„ ë° ì¡°ì–¸ ìˆ˜ì§‘
        print("\nğŸ” 3ë‹¨ê³„: ì²­í¬ë³„ ë¶„ì„")
        advice_list = []
        similar_past_diaries = []
        
        for i, chunk in enumerate(chunks, 1):
            print(f"\n   ğŸ“– ì²­í¬ {i} ë¶„ì„:")
            print(f"   ë‚´ìš©: {chunk[:100]}...")
            
            # ê°ì •/ìƒí™© ì¶”ì¶œ
            emotion, situation = self.extract_emotion_situation(chunk)
            print(f"   ê°ì •: {emotion}")
            print(f"   ìƒí™©: {situation}")
            
            if emotion and situation:
                # ì¹´í…Œê³ ë¦¬ ë§¤í•‘
                emotion_category, situation_category = self.map_to_categories(emotion, situation)
                print(f"   ë§¤í•‘ëœ ê°ì • ì¹´í…Œê³ ë¦¬: {emotion_category}")
                print(f"   ë§¤í•‘ëœ ìƒí™© ì¹´í…Œê³ ë¦¬: {situation_category}")
                
                if emotion_category and situation_category:
                    # í˜„ì¬ ì²­í¬ ì„ë² ë”© ìƒì„±
                    current_embedding_diary = self.embed_text_diary(chunk)
                    current_embedding = self.embed_text_general(chunk)
                    print(f"   ì„ë² ë”© ìƒì„± ì™„ë£Œ (ì¼ê¸°ìš©: {len(current_embedding_diary)}ì°¨ì›, ì¼ë°˜ìš©: {len(current_embedding)}ì°¨ì›)")
                    
                    # ìœ ì‚¬í•œ ê³¼ê±° ì¼ê¸° ê²€ìƒ‰
                    similar_diaries = self.find_similar_past_diaries(current_embedding_diary, user_id)
                    similar_past_diaries.extend(similar_diaries)
                    print(f"   ìœ ì‚¬í•œ ê³¼ê±° ì¼ê¸°: {len(similar_diaries)}ê°œ")
                    for j, diary in enumerate(similar_diaries[:2], 1):  # ìƒìœ„ 2ê°œë§Œ ì¶œë ¥
                        print(f"     {j}. {diary[:80]}...")
                    
                    # ì¼ê¸° ì €ì¥
                    chunk_id = f"{user_id}_{datetime.now().strftime('%Y%m%d%H%M%S')}_{i}"
                    today = datetime.now().strftime('%Y.%m.%d')
                    self.pre_diary_col.add(
                        documents=[chunk],
                        metadatas=[{
                            "user_id": user_id,
                            "date": today,
                            "emotion": emotion_category,
                            "situation": situation_category
                        }],
                        ids=[chunk_id]
                    )
                    print(f"   ì¼ê¸° ì €ì¥ ì™„ë£Œ (ID: {chunk_id})")
                    
                    # ê´€ë ¨ ì¡°ì–¸ ê²€ìƒ‰
                    chunk_advice_list = self.find_relevant_advice(current_embedding, emotion_category, situation_category)
                    advice_list.extend(chunk_advice_list)
                    print(f"   ê´€ë ¨ ì¡°ì–¸: {len(chunk_advice_list)}ê°œ")
                    for j, advice in enumerate(chunk_advice_list[:2], 1):  # ìƒìœ„ 2ê°œë§Œ ì¶œë ¥
                        print(f"     {j}. {advice[:80]}...")
                else:
                    print("   âŒ ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ì‹¤íŒ¨")
            else:
                print("   âŒ ê°ì •/ìƒí™© ì¶”ì¶œ ì‹¤íŒ¨")
        
        # 4. ìµœì¢… ì¡°ì–¸ ìƒì„±
        print(f"\nğŸ’¡ 4ë‹¨ê³„: ìµœì¢… ì¡°ì–¸ ìƒì„±")
        print(f"   ìˆ˜ì§‘ëœ ì¡°ì–¸ ìˆ˜: {len(advice_list)}ê°œ")
        print("   ì¡°ì–¸ ë¦¬ìŠ¤íŠ¸:")
        for i, advice in enumerate(advice_list, 1):
            print(f"     {i}. {advice}")
        
        final_advice = self.generate_final_advice(advice_list)
        print(f"   ìµœì¢… í†µí•© ì¡°ì–¸: {final_advice}")
        
        # 5. ê´€ë ¨ ì¸ìš©ë¬¸ ê²€ìƒ‰
        print(f"\nğŸ’¬ 5ë‹¨ê³„: ê´€ë ¨ ëª…ì–¸ ê²€ìƒ‰")
        quote = self.find_relevant_quote(final_advice) if final_advice else None
        print(f"   ì°¾ì€ ëª…ì–¸: {quote}")
        
        # 6. AI ì½”ë©˜íŠ¸ ìƒì„±
        print(f"\nğŸ¤– 6ë‹¨ê³„: AI ì½”ë©˜íŠ¸ ìƒì„±")
        comment = self.generate_comment(processed_diary, final_advice or "", similar_past_diaries, quote)
        print(f"   ìƒì„±ëœ ì½”ë©˜íŠ¸: {comment[:200]}...")
        
        # 7. ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ
        print(f"\nğŸ­ 7ë‹¨ê³„: ê°ì • í‚¤ì›Œë“œ ì¶”ì¶œ")
        emotion_keywords = self.extract_emotion_keywords(chunks)
        print(f"   ì¶”ì¶œëœ ê°ì • í‚¤ì›Œë“œ: {emotion_keywords}")
        
        print("\n" + "="*80)
        print("âœ… ì¼ê¸° ë¶„ì„ ì™„ë£Œ")
        print("="*80)
        
        return DiaryAnalysisResponse(
            processed_diary=processed_diary,
            chunks=chunks,
            advice=final_advice,
            comment=comment,
            quote=quote,
            emotion_keywords=emotion_keywords,
            similar_past_diaries=similar_past_diaries
        ) 